{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT SMOKER_ID_130.txt      [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_133.txt      [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_223.txt      [0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
      "CURRENT SMOKER_ID_236.txt      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_241.txt      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_25.txt       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "CURRENT SMOKER_ID_31.txt       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_43.txt       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_73.txt       [0, 0, 0, 1, 0, 0, 0, 0, 0, 4]\n",
      "CURRENT SMOKER_ID_85.txt       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_212.txt          [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_249.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_27.txt           [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_282.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_320.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_331.txt          [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "NON-SMOKER_ID_345.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_36.txt           [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_363.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_9.txt            [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_143.txt         [0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "PAST SMOKER_ID_154.txt         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_239.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "PAST SMOKER_ID_257.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_272.txt         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_278.txt         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_295.txt         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_326.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "PAST SMOKER_ID_344.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_368.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "UNKNOWN_ID_10.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_16.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_2.txt               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_22.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_3.txt               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_30.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_40.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_49.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_68.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_7.txt               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = {}\n",
    "vocab_word = {}\n",
    "i = 1\n",
    "catagory = [\"smoking\",'smoker','smokes','smoked','smoke','cigarette','cigarettes','cigar','tobacco','tobacco abuse']\n",
    "\n",
    "path = \"train/\"\n",
    "for filename in os.listdir(path):\n",
    "    \n",
    "    \n",
    "    for word in catagory:\n",
    "        if word in vocab:\n",
    "            continue\n",
    "        else:\n",
    "            vocab[word]=i\n",
    "            vocab_word[i]=word\n",
    "            i+=1\n",
    "    one = [0]*len(vocab)\n",
    "\n",
    "\n",
    "    with open(os.path.join(path, filename),'r') as txt:\n",
    "\n",
    "        x = txt.read().lower().split()\n",
    "        \n",
    "\n",
    "    for word in x:\n",
    "        try:\n",
    "            one[vocab[word]]+=1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    #     one[vocab[word]]+=1\n",
    "\n",
    "\n",
    "#     print(one)\n",
    "    print('{0:30} {1}'.format(filename, one))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT SMOKER_ID_130.txt      [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_133.txt      [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_223.txt      [0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
      "CURRENT SMOKER_ID_236.txt      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_241.txt      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_25.txt       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "CURRENT SMOKER_ID_31.txt       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_43.txt       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "CURRENT SMOKER_ID_73.txt       [0, 0, 0, 1, 0, 0, 0, 0, 0, 4]\n",
      "CURRENT SMOKER_ID_85.txt       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_212.txt          [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_249.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_27.txt           [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_282.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_320.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_331.txt          [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "NON-SMOKER_ID_345.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_36.txt           [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "NON-SMOKER_ID_363.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "NON-SMOKER_ID_9.txt            [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_143.txt         [0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "PAST SMOKER_ID_154.txt         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_239.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "PAST SMOKER_ID_257.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_272.txt         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_278.txt         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_295.txt         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_326.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "PAST SMOKER_ID_344.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "PAST SMOKER_ID_368.txt         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "UNKNOWN_ID_10.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_16.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_2.txt               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_22.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_3.txt               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_30.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_40.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_49.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_68.txt              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "UNKNOWN_ID_7.txt               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "conditions , infections , complications , affecting treatment / stay smoker htn atyp cp ( neg exer echo ) gerd dm ( diabetes mellitus ) 0\n",
      "atypical cp 54 yo smoker , hx of hyperlipidemia , htn , dm , tah / bso age 48 , and hx of atypical cp . 0\n",
      "current smoker , history of ; depression , history of ; isoimmunization , rh ; undesired fertility 0\n",
      "conditions , infections , complications , affecting treatment / stay htn tobacco etoh abuse sinus bradycardia 0\n",
      "fh , htn , tobacco . 0\n",
      "he admits to an approximately 25-50 pack year smoking history , and social alcohol use . 0\n",
      "positive smoking history . 0\n",
      "the patient 's cardiac risk factors include hypertension , hypercholesterolemia and tobacco use . 0\n",
      "she smokes two to three packs per day times 30 years . 0\n",
      "the patient smokes two packs per day and has an approximately a 75-pack-year history of smoking . 0\n",
      "the patient smokes two packs per day and has an approximately a 75-pack-year history of smoking . 0\n",
      "she smokes one pack per day x45 years . 0\n",
      "conditions , infections , complications , affecting treatment / stay crack use , tobacco use , schizoaffective d / o 0\n",
      "hpi. 51f w h / o tobacco and crack use p / w sob / doe worsening over the past 3 weeks and breast soreness , with troponin 0.15 in ed . 0\n",
      "schizoaffective f / b lumnerow health , crack use , tobacco , cri , fibroids , s / p i and d of breast abscess , htn 0\n",
      "lives alone , on ssdi , 1.5 ppd x > 10yrs , rare etoh , smokes crack several times per week , no ivdu 0\n",
      "a / p. 51f chronic tobacco , crack , schizoaffective and likely osa p / w doe / sob . 0\n",
      "53 yo m with h / o hyperchol , htn , tobacco use , fh heart disease p / w 3 wks chest pressure . 0\n",
      "patient does not smoke . 1\n",
      "denies tobacco , alcohol or drug use . 1\n",
      "no smoking , no alcohol . 1\n",
      "she denies any history of alcohol or tobacco use . 1\n",
      "she denies cigarette use and ethanol use as well as a recreational drug use . 1\n",
      "the patient denies tobacco and / or alcohol use . 1\n",
      "occasional alcohol , does not smoke . 1\n",
      "the patient denies any tobacco , alcohol , or drug use . 1\n",
      "patient does not smoke . 1\n",
      "she quit smoking tobacco in 1985 . 2\n",
      "she quit smoking tobacco in 1985 . 2\n",
      "the patient quit smoking 30 years ago . 2\n",
      "the patient quit tobacco in 1977 , no alcohol . 2\n",
      "smoked in the past . 2\n",
      "47 yo male with pmhx hyperlipidemia and former smoker here for evaluation of exertional chest tightness and dyspnea for the past two weeks . 2\n",
      "the patient was a prior off-and-on smoker but has quit in 01/19 . 2\n",
      "tobacco : 2\n",
      "she is a former tobacco user and takes no illicit drugs . 2\n"
     ]
    }
   ],
   "source": [
    "catagory = [\"smoking\",'smoker','smokes','smoked','smoke','cigarette','cigarettes','cigar','tobacco','tobacco abuse']\n",
    "\n",
    "path = \"train/\"\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "for filename in os.listdir(path):\n",
    "    \n",
    "\n",
    "\n",
    "    for word in catagory:\n",
    "        if word in vocab:\n",
    "            continue\n",
    "        else:\n",
    "            vocab[word]=i\n",
    "            vocab_word[i]=word\n",
    "            i+=1\n",
    "    one = [0]*len(vocab)\n",
    "\n",
    "\n",
    "    with open(os.path.join(path, filename),'r') as txt:\n",
    "\n",
    "        x = txt.read().lower().split('\\n')\n",
    "        #re.split('\\n|.',x)\n",
    "\n",
    "    for sentance in x:\n",
    "        words = sentance.split()\n",
    "        for word in words:\n",
    "            try:\n",
    "                one[vocab[word]]+=1\n",
    "                x_train.append(sentance)\n",
    "                if re.match(\"CURRENT SMOKER_ID_\\d+.txt\", filename):\n",
    "                    y_train.append(0)\n",
    "                elif re.match(\"NON-SMOKER_ID_\\d+.txt\", filename):\n",
    "                    y_train.append(1)\n",
    "                elif re.match(\"PAST SMOKER_ID_\\d+.txt\", filename):\n",
    "                    y_train.append(2)\n",
    "                elif re.match(\"UNKNOWN_ID_\\d+.txt\", filename):\n",
    "                    y_train.append(3)\n",
    "                \n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "#     print(one)\n",
    "    print('{0:30} {1}'.format(filename, one))\n",
    "#print(x_train)\n",
    "for i in range(len(x_train)):\n",
    "    print(x_train[i],y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 132)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train) # remember to use the original X_train set\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_tfidf,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 1]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(metrics.confusion_matrix(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91         6\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       0.75      1.00      0.86         3\n",
      "\n",
      "avg / total       0.93      0.91      0.91        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input txt file to classify from test file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0---current smoker    1---non smoker    2---past smoker    3---unknown\n",
      "\n",
      "TEST_01.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 2--- past smoker\n",
      "TEST_02.txt          [0, 0, 1, 0, 0, 0, 1, 0, 0, 0] 0--- current smoker\n",
      "TEST_03.txt          [0, 3, 0, 0, 0, 0, 0, 0, 0, 0] 2--- past smoker\n",
      "TEST_04.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 2--- past smoker\n",
      "TEST_05.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 0--- current smoker\n",
      "TEST_06.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 1--- non smoker\n",
      "TEST_07.txt          [0, 0, 1, 0, 0, 0, 0, 1, 0, 0] 0--- current smoker\n",
      "TEST_08.txt          [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] 1--- non smoker\n",
      "TEST_09.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_10.txt          [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] 1--- non smoker\n",
      "TEST_11.txt          [0, 2, 0, 0, 0, 0, 0, 0, 0, 0] 2--- past smoker\n",
      "TEST_12.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 0--- current smoker\n",
      "TEST_13.txt          [0, 1, 0, 0, 0, 0, 0, 1, 0, 0] 0--- current smoker\n",
      "TEST_14.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 2--- past smoker\n",
      "TEST_15.txt          [0, 2, 0, 0, 0, 0, 0, 0, 0, 0] 0--- current smoker\n",
      "TEST_16.txt          [0, 0, 0, 0, 0, 1, 0, 0, 0, 1] 1--- non smoker\n",
      "TEST_17.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_18.txt          [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] 1--- non smoker\n",
      "TEST_19.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_20.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 2--- past smoker\n",
      "TEST_21.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_22.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_23.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 1--- non smoker\n",
      "TEST_24.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_25.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_26.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_27.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 0--- current smoker\n",
      "TEST_28.txt          [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] 0--- current smoker\n",
      "TEST_29.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_30.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] 0--- current smoker\n",
      "TEST_31.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_32.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_33.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_34.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_35.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 2--- past smoker\n",
      "TEST_36.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_37.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n",
      "TEST_38.txt          [0, 1, 0, 0, 0, 0, 1, 0, 0, 1] 0--- current smoker\n",
      "TEST_39.txt          [0, 1, 0, 0, 0, 0, 0, 0, 0, 1] 0--- current smoker\n",
      "TEST_40.txt          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 3--- unknown\n"
     ]
    }
   ],
   "source": [
    "catagory = [\"smoking\",'smoker','smokes','smoked','smoke','cigarette','cigarettes','cigar','tobacco','tobacco abuse']\n",
    "\n",
    "path = \"test/\"\n",
    "x_train=[]\n",
    "file_name = []\n",
    "one_for_keyword = []\n",
    "category = []\n",
    "categroy_temp = 0\n",
    "\n",
    "\n",
    "for word in catagory:\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word]=i\n",
    "        vocab_word[i]=word\n",
    "        i+=1\n",
    "            \n",
    "            \n",
    "for filename in os.listdir(path):\n",
    "        \n",
    "    one = [0]*len(vocab)\n",
    "\n",
    "\n",
    "    with open(os.path.join(path, filename),'r') as txt:\n",
    "\n",
    "        x = txt.read().lower().split('\\n')\n",
    "\n",
    "    for sentance in x:\n",
    "        words = sentance.split()\n",
    "        for word in words:\n",
    "            try:\n",
    "                one[vocab[word]]+=1\n",
    "                x_train.append(sentance)\n",
    "                categroy_temp = text_clf.predict([sentance])[0]\n",
    "            except KeyError:\n",
    "                continue\n",
    "    \n",
    "    file_name.append(filename)\n",
    "    one_for_keyword.append(one)\n",
    "    \n",
    "    if one == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]:\n",
    "        category.append(3)\n",
    "    else:\n",
    "        category.append(categroy_temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predictions = text_clf.predict([x_train[1]])\n",
    "print('0---current smoker    1---non smoker    2---past smoker    3---unknown\\n')\n",
    "category_print = 0 \n",
    "for i in range(len(file_name)):\n",
    "\n",
    "    if category[i] == 0:\n",
    "        category_print = \"current smoker\"\n",
    "    elif category[i] == 1:\n",
    "        category_print = \"non smoker\"\n",
    "    elif category[i]== 2:\n",
    "        category_print = \"past smoker\"\n",
    "    elif category[i] == 3:\n",
    "        category_print = \"unknown\"\n",
    "    print('{0:20} {1} {2}--- {3}'.format(file_name[i], one_for_keyword[i],category[i], category_print ))\n",
    "    \n",
    "# for i in range(len(x_train)):    \n",
    "#     print(x_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
